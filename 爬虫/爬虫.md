# [GitHub项目地址](https://github.com/)

## [测试网址](http://example.com)

```py
http://example.com
```

# 第一章 初见网络爬虫

## 1.1 网络连接

```python
from urllib.request import urlopen #库
html = urlopen('http://example.com') #读取url，成功访问后，urlopen() 会返回一个 HTTPResponse 对象，赋值给变量 html
print(html.read())# 返回HTML
```

返回的是：HTML 文件的原始字节流。

```python
b'<!doctype html><html lang="en"><head><title>Example Domain</title><meta name="viewport" content="width=device-width, initial-scale=1"><style>body{background:#eee;width:60vw;margin:15vh auto;font-family:system-ui,sans-serif}h1{font-size:1.5em}div{opacity:0.8}a:link,a:visited{color:#348}</style><body><div><h1>Example Domain</h1><p>This domain is for use in documentation examples without needing permission. Avoid use in operations.<p><a href="https://iana.org/domains/example">Learn more</a></div></body></html>\n'
```

可读性不高原因：

- 里面没有换行或缩进；

- 仍是字节格式（未解码成字符串）；

- 没经过格式化显示。

后续用 BeautifulSoup 解析 HTML

## 1.2 BeautifulSoup简介

它通过定位 HTML 标签来格式化和组织复杂的网页信息，用简单易用的 Python 对象为我们展现 XML 结构信息。

### 1.2.1 安装

[kaggle](https://www.kaggle.com/)上面的notebook自带这个库。

自行命令行安装：

```python
pip install beautifulsoup4
```

### 1.2.2 运行

```py
from urllib.request import urlopen
from bs4 import BeautifulSoup
html = urlopen('http://example.com')#加载url网址
bs = BeautifulSoup(html.read(), 'html.parser')#第一个参数是该对象所基于的 HTML 文本，第二个参数指定了你希望 BeautifulSoup 用来创建该对象的解析器(解析器差别不大)。
print(bs.h1)
```

### 1.2.3 可靠的网络连接以及异常的处理

```py
html = urlopen('http://www.pythonscraping.com/pages/page1.html')
```

这行代码主要发生两种异常：

• 网页在服务器上不存在（或者获取页面的时候出现错误）——返回 HTTPError

• 服务器不存在      ——URLError

```py
from urllib.request import urlopen
from urllib.error import HTTPError
from urllib.error import URLError
try:
 html = urlopen('http://example.com')
except HTTPError as e: #分支1
 print(e)
except URLError as e:#分支2
 print('The server could not be found!')
else:#正常运行的
 print('It Worked!')
```

函数式

```py
from urllib.request import urlopen
from urllib.error import HTTPError
from bs4 import BeautifulSoup

def getTitle(url):
    try:
        html = urlopen(url)
    except HTTPError as e:
        return None
    try:
        bs = BeautifulSoup(html.read(), 'html.parser')
        title = bs.body.h1  # 获取页面的 h1 标签
    except AttributeError as e:
        return None  # 如果找不到 h1 标签，就会抛出 AttributeError

    return title.get_text()  # 提取文本 (这里没有else是return代表着结束，else没有意义)

title = getTitle('https://www.iana.org/help/example-domains')
if title == None:
    print('Title could not be found')
else:
    print(title)
```

# 第二章 复杂HTML解析

## 2.1 不要一直使用锤子

复杂HTML文件，针对性的解析。

## 2.2 再端一碗BeautifulSoup

将介绍通过属性查找标签的方法，标签组的使用，以及标签解析树的导航过程。

基本上每个网站都有层叠样式表（cascading style sheet，CSS）。
